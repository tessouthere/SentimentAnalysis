{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Preprocessing to fit into VADER Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'deprecated' from 'typing_extensions' (/Users/tessanderson/anaconda3/lib/python3.10/site-packages/typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/confection/__init__.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, Extra, ValidationError, create_model\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelField\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     FieldSerializationInfo,\n\u001b[1;32m      6\u001b[0m     SerializationInfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ValidatorFunctionWrapHandler,\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/__init__.py:29\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     ArgsKwargs,\n\u001b[1;32m      8\u001b[0m     MultiHostUrl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     validate_core_schema,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m _sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/core_schema.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, Hashable, List, Set, Tuple, Type, Union\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m12\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deprecated' from 'typing_extensions' (/Users/tessanderson/anaconda3/lib/python3.10/site-packages/typing_extensions.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/spacy/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[1;32m      5\u001b[0m \u001b[39m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/spacy/errors.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal\n\u001b[1;32m      6\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mErrorsWithCodes\u001b[39;00m(\u001b[39mtype\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, code):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/spacy/compat.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mthinc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m copy_array\n\u001b[1;32m      6\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcPickle\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/thinc/__init__.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mabout\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m registry\n\u001b[1;32m      7\u001b[0m \u001b[39m# fmt: off\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mregistry\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/thinc/config.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcatalogue\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfection\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfection\u001b[39;00m \u001b[39mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Decorator\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/confection/__init__.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmain\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelMetaclass\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, create_model, ValidationError, Extra  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmain\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelMetaclass  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelField  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     FieldSerializationInfo,\n\u001b[1;32m      6\u001b[0m     SerializationInfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ValidatorFunctionWrapHandler,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclasses\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/__init__.py:29\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any \u001b[39mas\u001b[39;00m _Any\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     ArgsKwargs,\n\u001b[1;32m      8\u001b[0m     MultiHostUrl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     validate_core_schema,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m _sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m     32\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m NotRequired \u001b[39mas\u001b[39;00m _NotRequired\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/core_schema.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdecimal\u001b[39;00m \u001b[39mimport\u001b[39;00m Decimal\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, Hashable, List, Set, Tuple, Type, Union\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m12\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m TypedDict\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deprecated' from 'typing_extensions' (/Users/tessanderson/anaconda3/lib/python3.10/site-packages/typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "# Importing the necessary packages. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>@tiniebeany climate change is an interesting h...</td>\n",
       "      <td>792927353886371840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right...</td>\n",
       "      <td>793124211518832641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fabulous! Leonardo #DiCaprio's film on #climat...</td>\n",
       "      <td>793124402388832256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  \\\n",
       "0         -1  @tiniebeany climate change is an interesting h...   \n",
       "1          1  RT @NatGeoChannel: Watch #BeforeTheFlood right...   \n",
       "2          1  Fabulous! Leonardo #DiCaprio's film on #climat...   \n",
       "\n",
       "              tweetid  \n",
       "0  792927353886371840  \n",
       "1  793124211518832641  \n",
       "2  793124402388832256  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset for preprocessing.\n",
    "sentiment_data = pd.read_csv('twitter_sentiment_data.csv')\n",
    "sentiment_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43943 entries, 0 to 43942\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  43943 non-null  int64 \n",
      " 1   message    43943 non-null  object\n",
      " 2   tweetid    43943 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sentiment_data.info()\n",
    "# Dataset has no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@tiniebeany climate change is an interesting h...</td>\n",
       "      <td>792927353886371840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right...</td>\n",
       "      <td>793124211518832641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Fabulous! Leonardo #DiCaprio's film on #climat...</td>\n",
       "      <td>793124402388832256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @Mick_Fanning: Just watched this amazing do...</td>\n",
       "      <td>793124635873275904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @cnalive: Pranita Biswasi, a Lutheran from ...</td>\n",
       "      <td>793125156185137153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43938</th>\n",
       "      <td>positive</td>\n",
       "      <td>Dear @realDonaldTrump,\\nYeah right. Human Medi...</td>\n",
       "      <td>791307031919550464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43939</th>\n",
       "      <td>positive</td>\n",
       "      <td>What will your respective parties do to preven...</td>\n",
       "      <td>791316857403936768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @MikkiL: UN Poll Shows Climate Change Is th...</td>\n",
       "      <td>791357509101621249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43941</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @taehbeingextra: i still can$q$t believe th...</td>\n",
       "      <td>791390042136641537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43942</th>\n",
       "      <td>positive</td>\n",
       "      <td>@Likeabat77 @zachhaller \\n\\nThe wealthy + foss...</td>\n",
       "      <td>791401610308038656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43943 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            message  \\\n",
       "0      negative  @tiniebeany climate change is an interesting h...   \n",
       "1      positive  RT @NatGeoChannel: Watch #BeforeTheFlood right...   \n",
       "2      positive  Fabulous! Leonardo #DiCaprio's film on #climat...   \n",
       "3      positive  RT @Mick_Fanning: Just watched this amazing do...   \n",
       "4           NaN  RT @cnalive: Pranita Biswasi, a Lutheran from ...   \n",
       "...         ...                                                ...   \n",
       "43938  positive  Dear @realDonaldTrump,\\nYeah right. Human Medi...   \n",
       "43939  positive  What will your respective parties do to preven...   \n",
       "43940       NaN  RT @MikkiL: UN Poll Shows Climate Change Is th...   \n",
       "43941   neutral  RT @taehbeingextra: i still can$q$t believe th...   \n",
       "43942  positive  @Likeabat77 @zachhaller \\n\\nThe wealthy + foss...   \n",
       "\n",
       "                  tweetid  \n",
       "0      792927353886371840  \n",
       "1      793124211518832641  \n",
       "2      793124402388832256  \n",
       "3      793124635873275904  \n",
       "4      793125156185137153  \n",
       "...                   ...  \n",
       "43938  791307031919550464  \n",
       "43939  791316857403936768  \n",
       "43940  791357509101621249  \n",
       "43941  791390042136641537  \n",
       "43942  791401610308038656  \n",
       "\n",
       "[43943 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset uses the labels -1: Anti, 0: Neutral, 1: Pro, and 2: News.\n",
    "# We need to remove any entries under the label 2 as factual news does not fit with VADER pretrained model. \n",
    "def change_labels(data):\n",
    "    \n",
    "    labels = {-1: 'negative', 0: 'neutral', 1: 'positive'}\n",
    "    data['sentiment'] = data['sentiment'].map(labels)\n",
    "\n",
    "    return data[['sentiment', 'message', 'tweetid']]\n",
    "\n",
    "change_labels(sentiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43943 entries, 0 to 43942\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  34667 non-null  object\n",
      " 1   message    43943 non-null  object\n",
      " 2   tweetid    43943 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# We succesfully renamed and removed News from the sentiment column, but we need to drop the entries that go with News since we only removed the sentiment values, not the tweets.\n",
    "sentiment_data.info()\n",
    "# We do this using dropna()\n",
    "sentiment_data.dropna(subset=['sentiment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34667 entries, 0 to 43942\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   sentiment         34667 non-null  object\n",
      " 1   message           34667 non-null  object\n",
      " 2   tweetid           34667 non-null  int64 \n",
      " 3   vader_prediction  34667 non-null  object\n",
      " 4   cleaned           34667 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "sentiment_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will also convert message column to string for easier processing.\n",
    "sentiment_data['message']=sentiment_data['message'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      " @tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for 15 yes while the suv boom\n",
      "Tweet 2:\n",
      " RT @NatGeoChannel: Watch #BeforeTheFlood right here, as @LeoDiCaprio travels the world to tackle climate change https://t.co/LkDehj3tNn httÃ¢â‚¬Â¦\n",
      "Tweet 3:\n",
      " Fabulous! Leonardo #DiCaprio's film on #climate change is brilliant!!! Do watch. https://t.co/7rV6BrmxjW via @youtube\n",
      "Tweet 4:\n",
      " RT @Mick_Fanning: Just watched this amazing documentary by leonardodicaprio on climate change. We all think thisÃ¢â‚¬Â¦ https://t.co/kNSTE8K8im\n",
      "Tweet 5:\n",
      " Unamshow awache kujinga na iko global warming https://t.co/mhIflU7M1X\n"
     ]
    }
   ],
   "source": [
    "# To begin processing the messages for EDA, first we will print some messages to understand what adjustments need to be done to format, etc. \n",
    "for index, text in enumerate(sentiment_data['message'][0:5]):\n",
    "    print('Tweet %d:\\n'%(index+1),text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will expand contractions for better analysis using a dictionary of English Contractions from analyticsvidhya.com.\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "  def replace(match):\n",
    "    return contractions_dict[match.group(0)]\n",
    "  return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews\n",
    "sentiment_data['message']=sentiment_data['message'].apply(lambda x:expand_contractions(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will lowercase all the messages. \n",
    "sentiment_data['cleaned']=sentiment_data['message'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will remove digits and words containing digits.\n",
    "sentiment_data['cleaned'] = sentiment_data['cleaned'].apply(lambda x: re.sub('\\w*\\d\\w*','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we will remove punctuations in the messages. \n",
    "sentiment_data['cleaned'] = sentiment_data['cleaned'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extra spaces\n",
    "sentiment_data['cleaned']=sentiment_data['cleaned'].apply(lambda x: re.sub(' +', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      " tiniebeany climate change is an interesting hustle as it was global warming but the planet stopped warming for yes while the suv boom\n",
      "Tweet 2:\n",
      " rt natgeochannel watch beforetheflood right here as leodicaprio travels the world to tackle climate change httpstco httã¢â‚¬â¦\n",
      "Tweet 3:\n",
      " fabulous leonardo dicaprio is film on climate change is brilliant do watch httpstco via youtube\n",
      "Tweet 4:\n",
      " rt mickfanning just watched this amazing documentary by leonardodicaprio on climate change we all think thisã¢â‚¬â¦ httpstco\n",
      "Tweet 5:\n",
      " unamshow awache kujinga na iko global warming httpstco\n"
     ]
    }
   ],
   "source": [
    "# Now we can check how our text looks after cleaning.\n",
    "for index, text in enumerate(sentiment_data['cleaned'][0:5]):\n",
    "    print(\"Tweet %d:\\n\"%(index+1),text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'deprecated' from 'typing_extensions' (/Users/tessanderson/anaconda3/lib/python3.10/site-packages/typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/confection/__init__.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, Extra, ValidationError, create_model\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelField\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     FieldSerializationInfo,\n\u001b[1;32m      6\u001b[0m     SerializationInfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ValidatorFunctionWrapHandler,\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/__init__.py:29\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     ArgsKwargs,\n\u001b[1;32m      8\u001b[0m     MultiHostUrl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     validate_core_schema,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m _sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/core_schema.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, Hashable, List, Set, Tuple, Type, Union\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m12\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deprecated' from 'typing_extensions' (/Users/tessanderson/anaconda3/lib/python3.10/site-packages/typing_extensions.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Using SpaCy for removal of stopwords and lemmatization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# loading model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m,disable\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/spacy/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[1;32m      5\u001b[0m \u001b[39m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_default_warnings\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/spacy/errors.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal\n\u001b[1;32m      6\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mErrorsWithCodes\u001b[39;00m(\u001b[39mtype\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, code):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/spacy/compat.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mthinc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m copy_array\n\u001b[1;32m      6\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcPickle\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/thinc/__init__.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mabout\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m registry\n\u001b[1;32m      7\u001b[0m \u001b[39m# fmt: off\u001b[39;00m\n\u001b[1;32m      8\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mregistry\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/thinc/config.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcatalogue\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfection\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfection\u001b[39;00m \u001b[39mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m Decorator\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/confection/__init__.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmain\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelMetaclass\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, create_model, ValidationError, Extra  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmain\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelMetaclass  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelField  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     FieldSerializationInfo,\n\u001b[1;32m      6\u001b[0m     SerializationInfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ValidatorFunctionWrapHandler,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclasses\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/__init__.py:29\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any \u001b[39mas\u001b[39;00m _Any\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     ArgsKwargs,\n\u001b[1;32m      8\u001b[0m     MultiHostUrl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     validate_core_schema,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m _sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m     32\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m NotRequired \u001b[39mas\u001b[39;00m _NotRequired\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic_core/core_schema.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdecimal\u001b[39;00m \u001b[39mimport\u001b[39;00m Decimal\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, Hashable, List, Set, Tuple, Type, Union\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m12\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m TypedDict\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deprecated' from 'typing_extensions' (/Users/tessanderson/anaconda3/lib/python3.10/site-packages/typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "# Using SpaCy for removal of stopwords and lemmatization\n",
    "import spacy\n",
    "# loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tessanderson/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install and import nltk\n",
    "import nltk\n",
    "\n",
    "# Download the lexicon\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Import the lexicon \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "sent_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>vader_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40195</th>\n",
       "      <td>neutral</td>\n",
       "      <td>It$q$s so hot in NYC I$q$m schvitzing in my br...</td>\n",
       "      <td>680119968042758145</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40368</th>\n",
       "      <td>neutral</td>\n",
       "      <td>https://t.co/cA2LysdLOU Regearing the Global R...</td>\n",
       "      <td>686307413788524544</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28971</th>\n",
       "      <td>positive</td>\n",
       "      <td>A reporter returns to Ohio to discuss the chal...</td>\n",
       "      <td>937197316741779456</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39006</th>\n",
       "      <td>positive</td>\n",
       "      <td>RT @Glen4ONT: #FF Quebec climate champions, Ou...</td>\n",
       "      <td>662756923532574720</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>positive</td>\n",
       "      <td>since he thinks global warming is a hoax this ...</td>\n",
       "      <td>798969559218814976</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            message  \\\n",
       "40195   neutral  It$q$s so hot in NYC I$q$m schvitzing in my br...   \n",
       "40368   neutral  https://t.co/cA2LysdLOU Regearing the Global R...   \n",
       "28971  positive  A reporter returns to Ohio to discuss the chal...   \n",
       "39006  positive  RT @Glen4ONT: #FF Quebec climate champions, Ou...   \n",
       "6189   positive  since he thinks global warming is a hoax this ...   \n",
       "\n",
       "                  tweetid vader_prediction  \n",
       "40195  680119968042758145         negative  \n",
       "40368  686307413788524544          neutral  \n",
       "28971  937197316741779456         positive  \n",
       "39006  662756923532574720         positive  \n",
       "6189   798969559218814976         positive  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_output(output_dict):\n",
    "    sentiment = 'neutral'\n",
    "    if(output_dict['compound']>=0.05):\n",
    "        sentiment='positive'\n",
    "    elif(output_dict['compound']<=-0.05):\n",
    "        sentiment='negative'\n",
    "    return sentiment\n",
    "def predict_sentiment(text):\n",
    "    output_dict = sent_analyzer.polarity_scores(text)\n",
    "    return format_output(output_dict)\n",
    "\n",
    "# running the predictions\n",
    "sentiment_data['vader_prediction']=sentiment_data['message'].apply(predict_sentiment)\n",
    "sentiment_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34969856059076354\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.14      0.47      0.22      3990\n",
      "     neutral       0.25      0.26      0.26      7715\n",
      "    positive       0.62      0.36      0.45     22962\n",
      "\n",
      "    accuracy                           0.35     34667\n",
      "   macro avg       0.34      0.36      0.31     34667\n",
      "weighted avg       0.48      0.35      0.38     34667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(sentiment_data['sentiment'],sentiment_data['vader_prediction'])\n",
    "\n",
    "print(\"Accuracy: {}\\n\".format(accuracy))\n",
    "\n",
    "print(classification_report(sentiment_data['sentiment'], sentiment_data['vader_prediction']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
